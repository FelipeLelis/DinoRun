# Chrome-Dino-Reinforcement-Learning

NOTE: This repo is the basic implementation with few limitations. Please refer the new repo at https://github.com/Paperspace/DinoRunTutorial

https://blog.paperspace.com/dino-run/

A Deep Convolutional Neural Network to play Google Chrome's offline Dino Run game by learning action patterns from visual input using a model-less Reinforcement Learning Algorithm

<string>NOTE:</strong> This is a basic-implementation repository with some limitations. Please refer https://github.com/Paperspace/DinoRunTutorial where I've used a GPU VM for better results, with scores upto 4000


<p>Refer the jupyter notebook for detailed implementation :<br>
https://github.com/ravi72munde/Chrome-Dino-Reinforcement-Learning/blob/master/Reinforcement%20Learning%20Dino%20Run.ipynb


# Installation 
Start by cloning the repository
<br>
<br>
`$ git clone https://github.com/ravi72munde/Chrome-Dino-Reinforcement-Learning.git`
<br>
`Dependencies can be installed using pip install or conda install for Anaconda environment`<br><br>

<strong>Dependencies</strong>
- Python 3.6
- Selenium 
- OpenCV
- PIL
- Keras
- Chromium driver for Selenium


![gif](https://raw.githubusercontent.com/ravi72munde/Chrome-Dino-Reinforcement-Learning/master/img_data/trained_dino.gif)
<br/>
# Sample Game Play
https://youtu.be/0oOOqGFmlDs 
<br/>

